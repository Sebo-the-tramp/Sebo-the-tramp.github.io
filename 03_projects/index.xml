<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Sebastian Cavada</title><link>https://sebo-the-tramp.github.io/03_projects/</link><description>Recent content in Projects on Sebastian Cavada</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 06 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sebo-the-tramp.github.io/03_projects/index.xml" rel="self" type="application/rss+xml"/><item><title>A guide to COLMAP</title><link>https://sebo-the-tramp.github.io/03_projects/colmap-part1/</link><pubDate>Sat, 02 Nov 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/colmap-part1/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/colmap-part1/cover.png" alt="Featured image of post A guide to COLMAP" />&lt;h1 id="colmap---a-guide-for-optimal-results">COLMAP - a guide for optimal results
&lt;/h1>&lt;h2 id="intro">Intro
&lt;/h2>&lt;p>So I spent the last 2 months trying out how to properly use and optimize COLMAP. Unfortunately most informations are buried in github issues, pull requests. You can get 70% from the official deocumentation, but most of the remaining I had to get it from trial and error and countless hors of searching trough GitHub trying to figure out if people had the same problem as I did.&lt;/p>
&lt;p>I found out so far that there are 2 main methods to improve results and can be directly impact the reconstruction without complicated tweaks in the code.&lt;/p>
&lt;ol>
&lt;li>Better input. (garbage in, garbage out)&lt;/li>
&lt;li>Settings finetuning for reconstruction&lt;/li>
&lt;/ol>
&lt;p>I&amp;rsquo;ll mainly talk about this two and maybe with some BONUS.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/colmap-part1/meme1.png"
width="608"
height="684"
srcset="https://sebo-the-tramp.github.io/03_projects/colmap-part1/meme1_hu10654309975242616656.png 480w, https://sebo-the-tramp.github.io/03_projects/colmap-part1/meme1_hu14567556585693798149.png 1024w"
loading="lazy"
alt="Yes that was me"
class="gallery-image"
data-flex-grow="88"
data-flex-basis="213px"
>&lt;/p>
&lt;h3 id="context">Context
&lt;/h3>&lt;p>I am particularly interested in Large scale reconstructions from only images and visual clues. I think I chose the hardest path, but that is what I like. COLMAP has impressive results on small scale reconstruction, but when the number of images increase, and the kms that the reconstruction spans, there is where the real trubles are. For context I want to reconstruct around 1KM of my CAMPUS, and that has some challenges, plus the campus is very similar and many people lose themselves because of similarities, so I imagine why COLMAP has some shortcomings.&lt;/p>
&lt;h2 id="better-input">Better Input
&lt;/h2>&lt;p>COLMAP relies on SIFT to extract features. During my countless tests, I found that to be quite reliable in standard settings, and using more sophisticated feature matchers, only increased complexity without a worthy reward. So I will stick to it.&lt;/p>
&lt;p>What really mattered in the end, was to get the perfect time of the day and be able to capture with exactly the perfect lighting conditions. That improved the reconstruction drastically. Also I had to pick a time of the day where not many people are around because that will confuse the feature matching algorithm.&lt;/p>
&lt;p>I ended up waking up at 6.30 AM and walk around with 2 gopros and an helmet to get the perfect results. A little bit later and the sun would create the flares that will mess up with the features and ruine all the process.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Fisrt advice:&lt;/strong> choose the best light conditions you possibly can get&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;strong>Second advice:&lt;/strong> avoid crowds and moving objects to avoid heavy postprocessing and iterate on the ideas faster&lt;/p>
&lt;/blockquote>
&lt;p>Another thing that probably I casually discovered, is that if I walk a straight
line in front of me, the reconstruction is going to be suboptimal. Instead if I zig-zag, through the path, the result tend to be more accurate. At first the motivation for such a behaviour was unknown, but after carefully reading and understand the limitation of structure-from-motion, it was clearer that the problem becomes ill posed when following a co-linear motion.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Third advice:&lt;/strong> have a &amp;ldquo;zig-zag&amp;rdquo; movement while you capture the environment to avoid reconstruction &lt;strong>imprecisions&lt;/strong> or &lt;strong>failures&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;p>I&amp;rsquo;ll try to add more as I learn but for now this is it.&lt;/p>
&lt;h2 id="finetuning-settings">Finetuning settings
&lt;/h2>&lt;p>I really had to fight hard for this one. I tried to use the more robust and &lt;strong>slower&lt;/strong> method of more discriminative feature matching:&lt;/p>
&lt;p>&lt;code>--SiftExtraction.estimate_affine_shape=true and --SiftExtraction.domain_size_pooling=true. In addition, you should enable guided feature matching using: --SiftMatching.guided_matching=true.&lt;/code> from &lt;a class="link" href="https://colmap.github.io/faq.html#:~:text=%2D%2DSiftExtraction.estimate_affine_shape%3Dtrue%20and%20%2D%2DSiftExtraction.domain_size_pooling%3Dtrue.%20In%20addition%2C%20you%20should%20enable%20guided%20feature%20matching%20using%3A%20%2D%2DSiftMatching.guided_matching%3Dtrue." target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>It works but on extreme cases and at an enormous price, as it doesn&amp;rsquo;t even use the GPU. So I ended up sticking with the &amp;ldquo;Standard&amp;rdquo; procedure. I also only use sequential matching as videos benefits a lot from such processing strategy.&lt;/p>
&lt;p>An average reconstuction is done as following:&lt;/p>
&lt;ol>
&lt;li>Convert the video into a sequence of images&lt;/li>
&lt;li>Run COLMAP&lt;/li>
&lt;li>Enjoy (60% of the times)&lt;/li>
&lt;/ol>
&lt;p>My goal is to improve the likelyhood of success.&lt;/p>
&lt;h3 id="1-image-processing">1. Image processing
&lt;/h3>&lt;p>(Usually I deal with multiple cameras, that is why I heve the folder 00/ standing for the camera ID)&lt;/p>
&lt;p>First I create a folder and then run the following command. You can choose the FPS, experimentally I saw that 3 is the best, sometimes 2 is also good if the movement pace is slow (e.g. human walk) otherwise you can try 4 if there are holes in the reconstruction or errors, most of the times that should fix. If it doesn&amp;rsquo;t try 5 but most likely you need to go to the previous step and reiterate there.
(always talking for human walking velocity, if using bike or car, that is a whole differnt story)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">mkdir -p ./00/images
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ffmpeg -hwaccel auto -i ./video/GX010041.MP4 -vf &lt;span class="s2">&amp;#34;fps=4,scale=iw:ih&amp;#34;&lt;/span> -q:v &lt;span class="m">8&lt;/span> ./00/images/%06d.png
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2-run-colmap">2. Run COLMAP
&lt;/h2>&lt;p>After a lot of iteration the script I found to be the most succesfull is the following:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># RUN RECONSTRUCTION&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> &lt;span class="m">00&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;Running Feature Extractor&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># colmap feature_extractor --database_path ../database.db --image_path ../images --SiftExtraction.estimate_affine_shape 1 --SiftExtraction.domain_size_pooling 1 &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">colmap feature_extractor --database_path ./database.db --image_path ./images --ImageReader.single_camera_per_folder &lt;span class="m">1&lt;/span> --ImageReader.default_focal_length_factor 0.5 --ImageReader.camera_model OPENCV
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># # echo &amp;#34;Running feature matching...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># colmap exhaustive_matcher --database_path ./database.db --SiftMatching.max_distance 1 --SiftMatching.guided_matching 1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">colmap sequential_matcher --database_path ./database.db --SiftMatching.max_distance &lt;span class="m">1&lt;/span> --SiftMatching.guided_matching &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># # echo &amp;#34;Reconstructing 3D model...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">colmap mapper --database_path ./database.db --image_path ./images --output_path ./
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># # glomap mapper --database_path ./database.db --image_path ../image_0 --output_path ./glo&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;Showing result&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">colmap gui --import_path ./0 --database_path ./database.db --image_path ./images
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># colmap gui --import_path ./geo-registered-model --database_path ./database.db --image_path ./images&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You basically CD into your folder, find already images folder and run:&lt;/p>
&lt;ol>
&lt;li>feature extraction -&amp;gt; standard&lt;/li>
&lt;li>sequential matcher -&amp;gt; faster but only matching images that are close in &amp;ldquo;time&amp;rdquo;&lt;/li>
&lt;li>reconstruct the model&lt;/li>
&lt;li>Show the model. Usually is saved to 0. but if not, check how many other folder are created 0,1,2 etc&amp;hellip; based on how many reconstruction has been done.&lt;/li>
&lt;/ol>
&lt;p>Enjoy! now with a 90% chance of success!&lt;/p>
&lt;p>Let me know if you have other questions, and in the future I might release some comparison between GLOMAP and COLMAP if you are interested.&lt;/p></description></item><item><title>TinySplat</title><link>https://sebo-the-tramp.github.io/03_projects/tiny-splat/</link><pubDate>Tue, 01 Oct 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/tiny-splat/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/tinysplat_small.jpg" alt="Featured image of post TinySplat" />&lt;h1 id="tinysplat">Tinysplat
&lt;/h1>&lt;p>During my the journey to understand Gaussian Splatting, I created Tinysplat as a hands-on project to explore its foundational concepts. By breaking down the complex process into more manageable parts, I aimed to simplify and clarify the underlying mechanisms. In this post, I’ll share the insights and discoveries I’ve made along the way, shedding light on the essentials of Gaussian Splatting through the lens of my experience with Tinysplat.&lt;/p>
&lt;h2 id="what-is-gaussian-splatting">What is Gaussian Splatting?
&lt;/h2>&lt;p>Gaussian splatting is a novel explicit surface representation developed to represent the 3D structure of an object or an environment and then convert (rasterize) them into 2D images to be shown on our screens.&lt;/p>
&lt;p>The 2 most important pieces of this concept are: Gaussian and Splatting.&lt;/p>
&lt;h3 id="gaussians">Gaussians
&lt;/h3>&lt;p>Gaussians is a shorthand for Gaussian distribution, which we are familiar from statistics in 1 dimension. Hold tight because in this process the dimensions of the Gaussian distribution will go up to 2 and 3. The most intuitive way to think of a Gaussian in 3 dimensions (with a lot of abuse in notation) is to think about it as a balloon. Of this balloon we can control different proprieties such as the rotation, the color, the size, by inflating it more or less etc.
Turns out that in the Gaussian Splatting process, we build the environment by merging together many of these balloons of different dimensions and colors at different positions in the space. Take a look at the following image:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower_hu3943403685022499734.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower_hu2712116330969510316.jpeg 1024w"
loading="lazy"
alt="&amp;ldquo;The first Gaussian flower - an abstract way of thinking about Gaussian splatting&amp;rdquo;"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>You can think of a car being made of many balloons at different positions and different sizes and colors, but then you can observe this shape from many points and always understand that this is a car.
And this brings us to the second key concept: splatting.&lt;/p>
&lt;h3 id="splatting">Splatting
&lt;/h3>&lt;p>Splatting is not a new concept and it refers to the technique of rendering each pixel on your monitor as the combination of many Gaussian-shaped &amp;ldquo;splats&amp;rdquo; (or balloons) by blending each contribution of each balloon given the camera position.
You might wonder what is special about this technique. Well in a single words it is DIFFERENTIABLE. It means that we can run back-propagation to whatever loss we have and therefore manipulating the properties of every balloons in our scene. To some degree we can think of differentiability as being a human inside the room that can listen to our commands shouting from a small window telling him where he should move every balloon to create an object. Without differentiability we would not have a way to communicate to the person inside.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation_hu6562073399138009442.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation_hu14846136555838797151.jpeg 1024w"
loading="lazy"
alt="Communication between the &amp;ldquo;Representation&amp;rdquo; on the left and the &amp;ldquo;Loss&amp;rdquo; on the right"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>Imagine there is no &amp;ldquo;open window&amp;rdquo; and no way for the two guys to communicate. Then the process will be NON differentiable. It is exactly the communication that was the key to enable many interesting applications of Gaussian splatting. Remember &amp;ldquo;Communication is key&amp;rdquo;.&lt;/p>
&lt;h2 id="but-why">But why?
&lt;/h2>&lt;p>Then you might ask why do we need to have a man inside a house inflating balloons and one guy outside observing and shouting?! Well that&amp;rsquo;s a fair question.&lt;/p>
&lt;p>In proper terminology what this techniques enable is to learn from just a handful of images, on the order of the hundreds, a whole object or environment, so hopefully we can generate &amp;ldquo;novel views&amp;rdquo;. This fancy term refers basically that we can generate a rough 3D reconstruction from these images.
Again in technical terms we are over-fitting a scene or also inferring from the images we have at our disposal, what would the image look like from a completely different point of view that we didn&amp;rsquo;t have before.&lt;/p>
&lt;p>In conclusion this technique is called explicit neural radiance Field. The explicit term references the fact that the parameters of the Gaussians are stored as is, and in the weights as in the NeRF representation for example. Radiance field instead is just a fancy word that was chosen to describe the way that rays are captured by the camera coming from all the scene.&lt;/p>
&lt;h2 id="okay-balloons-and-communication-now-what">Okay, balloons and communication, now what?
&lt;/h2>&lt;p>This is a legit question. How do we even generate these Gaussians, and even how do we position them? We don&amp;rsquo;t have a human in the computer, let alone 2 people communicating!&lt;/p>
&lt;p>The journey of creating a realistic scene is split into 2 parts:&lt;/p>
&lt;ol>
&lt;li>Initialization of the priors&lt;/li>
&lt;li>Fitting of the priors onto the images&lt;/li>
&lt;/ol>
&lt;h3 id="priors-initialization">Priors initialization
&lt;/h3>&lt;p>Gaussian splatting works better if we have already a rough idea of what the scene looks like. Imagine having some rough sketch of what you want, it is going to be easier to realize your masterpiece. In the same way, Gaussian Splatting works best when our initial sketch is a Point Cloud. A point cloud is exactly a way to define a rough sketch of the scene.&lt;/p>
&lt;p>The most common way to obtain is to run an algorithm called Structure from Motion. In other words given images of the scene from different positions it will triangulate the points and create a 3D representation which is close enough to reality. These methods are still improving and there is no best approach but it depends on many factors such as dimensions, motions etc. In the end this is still an open research question, therefore many more options (hopefully) are coming every month.&lt;/p>
&lt;p>Here you can have a look of what that means. The red &amp;ldquo;things&amp;rdquo; (camera frustums), represent the rotation and position of the cameras in space, whilst the points (which should be colored), they represent the 4D space that was reconstructed. It is called &amp;ldquo;sparse&amp;rdquo; reconstruction because as you might have noticed, it is missing a lot of points, but the 3D high level idea can be interpreted by a human at least.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example.png"
width="1559"
height="1028"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example_hu9886606328979335903.png 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example_hu15624097298807457446.png 1024w"
loading="lazy"
alt="Structure from motion from the Abu Dhabi F1 circuit"
class="gallery-image"
data-flex-grow="151"
data-flex-basis="363px"
>&lt;/p>
&lt;p>Once this rough initialization has been created is time to go to next step.&lt;/p>
&lt;h3 id="fitting-of-the-gaussians-more-technical">Fitting of the Gaussians (more technical)
&lt;/h3>&lt;p>This part is the most mindblowing and difficult, so take a deep breath and let&amp;rsquo;s dive into cold waters.&lt;/p>
&lt;p>Now that we have some images, the position and rotation of the cameras, where the image was taken and the priors point cloud, the real training begins.&lt;/p>
&lt;p>It works very similar as in neural networks, where we have a set of parameters that needs to optimized using some gradient descent algorithm such as SGD. In this case all gaussians are initialized with the color and point in 3D space provided by the SfM algorithm. The scale and rotations are initialized as standard values such as 1.&lt;/p>
&lt;p>During training we use these values to create and project the Gaussians onto the screen in a &lt;strong>differentiable manner&lt;/strong>. This will produce some strange images at first, by projecting all the gaussians to the screen that is orientated and positioned in the same way as the way the image was taken.&lt;/p>
&lt;p>This way we have a reference of what the image should be at that position, and what we actually get from the &amp;ldquo;splatting&amp;rdquo; process. Now you might have understood already, we can calculate a &lt;strong>loss&lt;/strong> or &lt;strong>difference&lt;/strong> in similarity between the two images. There are 2 ways this difference is computed, and usually is a combination of different losses such as f1 loss, and SSIM loss, where $\lambda$ is a parameter used to balance the two accuracies.&lt;/p>
&lt;p>$$
(1 - \lambda) * \text{F1-loss(img1, img2)} + \lambda * \text{SSIM(img1, img2)}
$$&lt;/p>
&lt;p>In this way iterating over the many images in the dataset, batch by batch, we can optimize the parameters of the whole number of Gaussians by backpropagating the error back to each gaussian based on the (sum) of the error(s) from every pixel in each image.
By optimizing these parameters, after some epochs, a clear image can be seen. A 2D example is displayed below. What you see is a video of the training where the Gaussians gets progressively refined and the final result is a sharp and crisp image.&lt;/p>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4"
poster="./flower.jpeg"
autoplay
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;p>(&lt;em>Video courtesy of&lt;/em> &lt;a class="link" href="https://github.com/OutofAi/2D-Gaussian-Splatting" target="_blank" rel="noopener"
>OutOfAI&lt;/a>)&lt;/p>
&lt;h3 id="final-thoughts">Final thoughts
&lt;/h3>&lt;p>This is a good introductory article to Gaussian splatting in a non-technical way. If you would like to dig deeper into the topics I am compiling a series of blog post where I show the implementation of Gaussian Splatting in 2D &lt;a class="link" href="https://sebo-the-tramp.github.io/04_notebook/tinysplat/" target="_blank" rel="noopener"
>here&lt;/a> and in the future also in 3D.&lt;/p>
&lt;p>I will leave another list of good material that helped me understand better the topic. Let me know if this was helpful, and especially how I can improve!&lt;/p></description></item><item><title>My first hackathon in the UAE - Pioneers 4.0 - (🏆 WINNER)</title><link>https://sebo-the-tramp.github.io/03_projects/edge-hackathon/</link><pubDate>Mon, 04 Mar 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/edge-hackathon/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image.png" alt="Featured image of post My first hackathon in the UAE - Pioneers 4.0 - (🏆 WINNER)" />&lt;h1 id="my-first-hackathon-in-the-uae">My first Hackathon in the UAE
&lt;/h1>&lt;p>I had the opportunity to participate in the Pioneers4.0 Hackathon, organized by the Edge together with MoAT and partner LIPTON tea. It was a 72-hour event, where we had to develop an optimization solution to optimize the production and blending of tea.&lt;/p>
&lt;p>I was part of a team of 5 people, and we were able to develop a solution that was able to optimize the production of tea, considering the different types of tea and the different blends that could be made. We used a simple rule-based algorithm to optimize the production and blending of tea, and we were able to present a working prototype at the end of the event.&lt;/p>
&lt;p>It was a great experience, and I was able to learn a lot about the tea industry and the challenges that the industry faces. I also learned a lot about the different types of tea and the different blends that can be made. It was a great opportunity to work with a team of people from different backgrounds and to learn from each other.&lt;/p>
&lt;p>We also managed to win the competition with a mix of team-work, creativity as well as technical skills. It was a great experience and I am looking forward to participating in more hackathons in the future.&lt;/p>
&lt;p>Thanks to the Edge and MoAT for organizing the event, and to LIPTON tea as well. I am looking forward to be part of the LIPTON team in the future, with the internship that I was awarded at the end of the event.&lt;/p>
&lt;p>Following some pictures of the event:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image.png"
width="2996"
height="1096"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image_hu3037950491188731137.png 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image_hu12029488097392795760.png 1024w"
loading="lazy"
alt="All the participants together on the stage"
class="gallery-image"
data-flex-grow="273"
data-flex-basis="656px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19.JPG"
width="3840"
height="2160"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19_hu7768972869191826713.JPG 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19_hu5647556701346842885.JPG 1024w"
loading="lazy"
alt="Our winning proof"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1.JPG"
width="4032"
height="2268"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1_hu13038122089877568271.JPG 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1_hu17815644352049799312.JPG 1024w"
loading="lazy"
alt="Our amazing team, from left to right (people holding the cerificate): Luthfi Shahab, me, Segni Desalegn, Sara Abdulbasit, Mariam Alzaabi and Siti Maghfirotul Ulyah"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p></description></item><item><title>MBZUAI entrepreneurship school</title><link>https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/</link><pubDate>Sat, 20 Jan 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846.jpeg" alt="Featured image of post MBZUAI entrepreneurship school" />&lt;p>🚀 A Milestone at the Entrepreneurship Pitch Day 🌟&lt;/p>
&lt;p>What an enriching experience for WellRound during last week&amp;rsquo;s Pitch Day organized by MBZUAI (Mohamed bin Zayed University of Artificial Intelligence) and startAD as the conclusion of the MBZUAI Entrepreneurship Course. Our journey was packed with learning and invaluable insights!&lt;/p>
&lt;p>The chance to present our AI-driven idea to the esteemed jury members Jean-Luc Scherer, Sultan Al Hajji, Selim Tira, Dr Ramzi BEN OUAGHREM and Michael Huang was both challenging and rewarding. Their feedback is a treasure trove, guiding our next steps.&lt;/p>
&lt;p>Kudos to everyone at StartAD for the great opportunity, in particular, a huge thanks to Flo Akinbiyi, Adnan Dekedek, and Jenny Li for their enthusiasm and expert guidance!&lt;/p>
&lt;p>A big shoutout to the winners for their amazing pitches and ideas, and to everyone that participated!&lt;/p>
&lt;p>My colleagues Akbobek Abilkaiyrkyzy, Sathya R, and I are already gearing up for our Wellround&amp;rsquo;s next iteration, inspired and more focused than ever.&lt;/p>
&lt;p>🔑 Key Takeaways:&lt;/p>
&lt;ul>
&lt;li>Embrace every piece of feedback for growth.&lt;/li>
&lt;li>Each pitch sharpens our vision and storytelling.&lt;/li>
&lt;li>Collaboration fuels innovation.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846.jpeg"
width="2048"
height="1152"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846_hu6257078364664368816.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846_hu976951420474417839.jpeg 1024w"
loading="lazy"
alt="All the 2023 fall class of the MBZUAI Entrepreneurship school"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531_hu7245333940414877949.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531_hu4621521240127584442.jpeg 1024w"
loading="lazy"
alt="Receiving the certificate"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940_hu16103162977852578918.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940_hu872847728078529929.jpeg 1024w"
loading="lazy"
alt="A cool photo! In reality I was really trembling"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219_hu162178263792267735.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219_hu6058965238694885698.jpeg 1024w"
loading="lazy"
alt="Our amazing team, from left to right: me, Akbobek Abilkaiyrkyzy and Sathyamoorthy Rajendran"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p></description></item><item><title>Euregio Brussels school</title><link>https://sebo-the-tramp.github.io/03_projects/contexts/</link><pubDate>Sat, 08 Apr 2023 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/contexts/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/cover.jpeg" alt="Featured image of post Euregio Brussels school" />&lt;h1 id="part-1---the-plane">Part 1 - the plane
&lt;/h1>&lt;p>I am writing from the plane. I am in the first row in the middle. I feel I am very lucky. My week of lectures has ended this morning with a discussion on the migration problem in the EU. It was something I have never experienced because we had to take the side of the politicians that don’t accept or better want to protect the EU from immigration. Usually this is the opposite to what I think and it was good for me to push myself out of the bubble and try to see everything from a new prospective. I can’t lie that it was difficult to be in the shoes of people that uses hate and aversion towards the different and the unknown to get votes and get things done, because this is what it does boil down to.&lt;/p>
&lt;p>During this experience I really felt what it is to be on the other side and even more I realize how much I tend to be a “super-part” everyday life. Here is where the inception happens. Through meditation I learned to be equanimous and be balanced on most topics. Then reading the book “reality transurfing” in the past weeks I learned how wise and useful it is not to take any side in discussion or idealisms. And in the end this week I experienced the importance of taking a side and trying to be on the side of the right. And here I also see both the arguments to take a position and not to take a position. I am equanimous. According to the meditation we should always have in mind to reduce suffering and that’s what I have in mind for the future and I would always like to deploy all my resources towards this goal.
As a concluding anecdote, I wanted to share my experience with homeless people I met in Bruxelles, because yes where the most money are the most poverty is as well.&lt;/p>
&lt;p>This homeless people where there on the streets and I wanted to do anything to help. Probably I didn’t. I could have shared a loaf of bread that in the end I had to throw away. I could have brought them some items I have bought from too good to go, but I felt it was wrong and I felt embarrassed, but most of all I didn’t know if that was the right way to act. In this regard I think there is no, or very little, actions that can be done at that very moment to solve something, but I am a big fun of compounded interest and doing small, or big, things over a long period of time in order to really solve a problem.
This proved to be successful different times. Especially I realized this with my education: there was no single thing that I could have done different, because in the end they brought me at this point. Now I really want to focus only on a handful things, do them at a very high level and be able then to give value to many through my work and time. With this I want to say that we are in this together, we are all excellent at speaking or writing, but will we have the courage to act and really put our words into actions?&lt;/p>
&lt;p>I hope so and I will bring this experience with me and use it as a tool for my next decisions to be aligned with the goal of giving the most and making this place a little better because of my presence. If I could help a single person than my goal will be fulfilled.&lt;/p>
&lt;p>We are in a cloud now, there is some turbulence and I will have to close now.&lt;/p>
&lt;h1 id="part-2---the-train">Part 2 - the train
&lt;/h1>&lt;p>I start to write the second and conclusive part here in the train. I was able to get a good train going to Pandora and I am still active and I feel I would like to write or relax.
I still don’t believe what happened on the plane. It is so strange, yet so beautiful. Some times I think is karma other I just understand that it is only a coincidence. Maybe it was just how the algorithms of Ryanair works in assigning random places. Actually it probably don’t assign random all places but it will prefer the ones that has no additional value first. Then maybe I was a bit late for the check in and they first because all the others were already taken (?). This is a big supposition but I am grateful that happen, and at the same time I now realized that I should be equanimous and don’t crave this feelings but rather really live to the fullest every day.&lt;/p>
&lt;p>On this proposition I realized how better it is to really always try to live to the fullest. Life is short and it does not have any prefixed length. So living everyday in the present is the real life hack. And also memento more has become increasingly more important as if a person lives a life with a purpose and a direction whenever it will end it will be a good life. If someone might not have a purpose or direction that might be a bit more difficult.&lt;/p>
&lt;p>Let me know what you think in this regard in the comments and I will leave you with a couple of photos of my and our class in Bruxelles.&lt;/p>
&lt;p>Ciao!&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/e.jfif"
width="1600"
height="1200"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/e_hu722358435378867216.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/e_hu422797500594362348.jfif 1024w"
loading="lazy"
alt="At the EU Commission"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/c.jfif"
width="2000"
height="1500"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/c_hu12171015809121266458.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/c_hu9924231365313408728.jfif 1024w"
loading="lazy"
alt="At the Euregio representation in Bruxelles"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/d.jfif"
width="1600"
height="1200"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/d_hu15004275814929729284.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/d_hu753058859736929890.jfif 1024w"
loading="lazy"
alt="At the EU Parliament"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/b.jfif"
width="1024"
height="768"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/b_hu15812956490927628739.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/b_hu14911607811920133306.jfif 1024w"
loading="lazy"
alt="Chilling in the park"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/a.jfif"
width="1024"
height="768"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/a_hu3636863013617844214.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/a_hu16046551133804725612.jfif 1024w"
loading="lazy"
alt="Chilling at the beer factory"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p></description></item><item><title>Wurth 2022 - (🏆 WINNER)</title><link>https://sebo-the-tramp.github.io/03_projects/wurth-2022/</link><pubDate>Sun, 20 Nov 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/wurth-2022/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/wurth-2022/cover.jpeg" alt="Featured image of post Wurth 2022 - (🏆 WINNER)" />&lt;h1 id="wurth-2022">Wurth 2022
&lt;/h1>&lt;p>This was a cyber-security challenge, in particular a capture the flag. I was lucky to get accepted in a team where a friend of mine was, since I my team-mate was sick
that day. I ended up in a team of super cool guys as well as very smart and experienced people. I learned a lot from them and I hope I was able to help them as well.&lt;/p>
&lt;p>The challenges were 5 and after arriving 1 hour late, we were able to solve them all before every other team and with nearly half an hour of spare time. We were the first team to finish the challenge.&lt;/p>
&lt;p>I learned a lot and I was also able to give my small contribution, but without the team I would have never been able to do it.&lt;/p>
&lt;p>There we are:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/wurth-2022/1.jpg"
width="1280"
height="960"
srcset="https://sebo-the-tramp.github.io/03_projects/wurth-2022/1_hu13106872668401728591.jpg 480w, https://sebo-the-tramp.github.io/03_projects/wurth-2022/1_hu16151580714026315948.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p></description></item><item><title>HackaTUM 2022</title><link>https://sebo-the-tramp.github.io/03_projects/hackatum-2022/</link><pubDate>Fri, 18 Nov 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/hackatum-2022/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackatum-2022/cover.jpg" alt="Featured image of post HackaTUM 2022" />&lt;p>Pokemon Geo is our geo-tagging game built during HackaTUM 2022 (Huawei Challenge) based on OpenStreetMap (&lt;a class="link" href="https://www.openstreetmap.org" target="_blank" rel="noopener"
>https://www.openstreetmap.org&lt;/a>) and Mapillary (&lt;a class="link" href="https://www.mapillary.com" target="_blank" rel="noopener"
>https://www.mapillary.com&lt;/a>).&lt;/p>
&lt;p>In our app, the user is interacting with the real world by solving &amp;ldquo;issues&amp;rdquo;. While taking a walk, the player can take photos, tackle time-based challenges, compete in an online leaderboard and much more. At the same time, this helps OpenStreetMap improve their tags.&lt;/p>
&lt;p>We built our User Interface with Flutter, our backend with Flask and trained our photo classification model with PyTorch.&lt;/p>
&lt;p>We hope you have fun playing our game and we wish you a wonderful day!&lt;/p>
&lt;p>Gotta catch ‘em issues.&lt;/p>
&lt;p>This hackathon was a very fun one because I did not know anybody once I got there. I had to find a team and a challenge. I was really stressed and worried.
In the end it turned out great! I met a lot of people and I had a lot of fun, if you want to know more just check the VLOG on youtube.&lt;/p>
&lt;p>Following are some of the photos:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackatum-2022/1.JPEG"
width="2048"
height="1536"
srcset="https://sebo-the-tramp.github.io/03_projects/hackatum-2022/1_hu3811812547604244663.JPEG 480w, https://sebo-the-tramp.github.io/03_projects/hackatum-2022/1_hu14341200031209517358.JPEG 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackatum-2022/2.JPEG"
width="1536"
height="2048"
srcset="https://sebo-the-tramp.github.io/03_projects/hackatum-2022/2_hu8331677522728517416.JPEG 480w, https://sebo-the-tramp.github.io/03_projects/hackatum-2022/2_hu13033026818149733597.JPEG 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="75"
data-flex-basis="180px"
>&lt;/p></description></item><item><title>Hackathon NOI - November 2022 - (🏆 WINNER)</title><link>https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/</link><pubDate>Fri, 11 Nov 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/cover.jpg" alt="Featured image of post Hackathon NOI - November 2022 - (🏆 WINNER)" />&lt;p>The aim of our team was to develop a fully autonomous logistic system for hotels and vacations house to manage their laundry as well as textile such as curtains, carpets, and so on. The system relies on Arduino, to automate and track the movement and the current position of the textile in the facility.&lt;/p>
&lt;p>An app will also enable the staff members to read and update any value related to the articles of clothing.&lt;/p>
&lt;p>A dashboard will also be available to the management in order to have accurate monitoring of the situation as well as giving advice of the best and most efficient actions to be taken.&lt;/p>
&lt;p>There we are:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/1.jpg"
width="799"
height="533"
srcset="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/1_hu978244722853927065.jpg 480w, https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/1_hu4987364894958902381.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="359px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/3.jpg"
width="799"
height="533"
srcset="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/3_hu2971327980290071602.jpg 480w, https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/3_hu6759982170524883964.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="359px"
> &lt;img src="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/2.jpg"
width="799"
height="533"
srcset="https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/2_hu9718999671746849220.jpg 480w, https://sebo-the-tramp.github.io/03_projects/hackathonnoi-2023/2_hu7662371323479467280.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="359px"
>&lt;/p></description></item><item><title>HackZurich 2022 - (🏆 WINNER)</title><link>https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/</link><pubDate>Sun, 18 Sep 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/cover.jpg" alt="Featured image of post HackZurich 2022 - (🏆 WINNER)" />&lt;p>Out of the Blue is a versatile tool that allows anyone to obtain a detailed 4D model based on a 2D blueprint, unlocking a set of new services that vary from creating a perfect digital twin of the house (that supports smart automated routines to reduce risks) to an optimized instrument for crisis containment which could be a keystone tool into the daily work of firefighters.&lt;/p>
&lt;p>HackZurich is the biggest hackathon in Europe. It was a priviledge for me to be selected among the participants. Again I knew nobody, but in the end I met some old friends from other hackathons, we teamed up, we won and most importantly we had so much fun. Check out the VLOG on youtube.&lt;/p>
&lt;p>Following are some of the photos:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/0.jpg"
width="2048"
height="1536"
srcset="https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/0_hu13566798297993260026.jpg 480w, https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/0_hu470447693546895174.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/1.jpg"
width="3024"
height="1862"
srcset="https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/1_hu12426859067536009603.jpg 480w, https://sebo-the-tramp.github.io/03_projects/hackzurich-2022/1_hu3689888215123090986.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="162"
data-flex-basis="389px"
>&lt;/p></description></item><item><title>Osnahack - June 2022</title><link>https://sebo-the-tramp.github.io/03_projects/osnahack-2022/</link><pubDate>Sat, 18 Jun 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/osnahack-2022/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/osnahack-2022/cover.jpg" alt="Featured image of post Osnahack - June 2022" />&lt;p>While I was in Erasmus I had the pleasure to work with brilliant people, Sing, Pravir and Giulia, in an hackathon in the city I was doing my Erasmus in. It was a great experience when I think back. We didn&amp;rsquo;t win or anything, but we had so much fun and I personally learned a lot afterwards, overanalysing the experience and how it
turned out.&lt;/p>
&lt;p>This is what has been wrote about our project:&lt;/p>
&lt;blockquote>
&lt;p>Bagel sorgt dafür, dass Radfahrer sicher und effizient in Osnabrück unterwegs sind. Das wird durch die Daten von Google Maps, GPS und Ampelplänen auf der App möglich. Indem unsere Stadt fahrradfreundlicher wird, werden die Osnabrücker dazu ermutigt, ein saubereres, friedlicheres und nachhaltigeres Zuhause zu schaffen.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Osnahack, &lt;/span>&lt;a href="https://osnahack.de/rueckblick/">&lt;cite>Osnahack website&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>In english also:&lt;/p>
&lt;blockquote>
&lt;p>Bagel ensures that cyclists can travel safely and efficiently in Osnabrück. This is made possible by data from Google Maps, GPS and traffic light plans on the app. By making our city more bike-friendly, Osnabrückers are encouraged to create a cleaner, more peaceful and sustainable home.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Osnahack, &lt;/span>&lt;a href="https://osnahack.de/rueckblick/">&lt;cite>Osnahack website&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>There we are:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/osnahack-2022/1.jpg"
width="2560"
height="1707"
srcset="https://sebo-the-tramp.github.io/03_projects/osnahack-2022/1_hu627293474720840596.jpg 480w, https://sebo-the-tramp.github.io/03_projects/osnahack-2022/1_hu618370120143896027.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="149"
data-flex-basis="359px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/osnahack-2022/2.jpg"
width="960"
height="1280"
srcset="https://sebo-the-tramp.github.io/03_projects/osnahack-2022/2_hu16293842549924275010.jpg 480w, https://sebo-the-tramp.github.io/03_projects/osnahack-2022/2_hu1997604243972799898.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="75"
data-flex-basis="180px"
>&lt;/p>
&lt;p>The video of all the presentations, our presentation can be found at minute 55.&lt;/p>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/NFcjOHbGjsE"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div></description></item><item><title>Productflow 2021</title><link>https://sebo-the-tramp.github.io/03_projects/productflow-2021/</link><pubDate>Sun, 20 Mar 2022 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/productflow-2021/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/productflow-2021/cover.JPG" alt="Featured image of post Productflow 2021" />&lt;p>I presented this idea on a topic very near to me. That is mental health. It was the occasion in which I really get near to it.&lt;/p>
&lt;p>It was the opportunity to learn about a new thing. Produce what I always liked, ideas. Startup-ideas.&lt;/p>
&lt;p>I was selected among 40 finalist that have been invited to Milan, at the Bending spoons headquarters. It was an amazing experience.&lt;/p>
&lt;p>I met some of the most brilliant mind I&amp;rsquo;ve ever met. I had the honour and luck to be able to talk to the 3 winners even before they were announced. As if I had a
6th sense of where greatness can be found. Jokes apart it was one of the best experiences of growth, emotions and learning in a couple of year.&lt;/p>
&lt;p>In the photo you can see me casually at the centre, usually I am not there but this time I felt at home. With like-minded people. One of the best feelings in the world.&lt;/p>
&lt;p>There we are:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/productflow-2021/3.jpg"
width="800"
height="533"
srcset="https://sebo-the-tramp.github.io/03_projects/productflow-2021/3_hu14291640209341161729.jpg 480w, https://sebo-the-tramp.github.io/03_projects/productflow-2021/3_hu2765747644746522546.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
> &lt;img src="https://sebo-the-tramp.github.io/03_projects/productflow-2021/2.jpg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/productflow-2021/2_hu13057425231475658340.jpg 480w, https://sebo-the-tramp.github.io/03_projects/productflow-2021/2_hu9851262325008844586.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/productflow-2021/1.jpg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/productflow-2021/1_hu6114087879880615919.jpg 480w, https://sebo-the-tramp.github.io/03_projects/productflow-2021/1_hu14172087368995546087.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p></description></item><item><title>Climathon</title><link>https://sebo-the-tramp.github.io/03_projects/climathon-2021/</link><pubDate>Sat, 20 Nov 2021 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/climathon-2021/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/climathon-2021/cover.jpg" alt="Featured image of post Climathon" />&lt;p>In the summer of 2021, I received an email. It was from the European association Climate-KIC, an European community that works to accelerate the transition to a zero emission
world. The email said: organize a climathon in your City. And that is what happened.&lt;/p>
&lt;p>I asked around if there was some interest in such an event, and I got a good feedback from Veronica a friend of my town. Together we said, let&amp;rsquo;s do it.&lt;/p>
&lt;p>After many days, many calls, many emails, and many associations contacted, we were able to organize and successfully run a climathon in our Valley.&lt;/p>
&lt;p>It was an amazing experience. 40 people showed up and 7 projects were created to tackle our local challenges. Everybody was happy and so were we. I met so many new
people and young talents full of energy and desire to build, create and innovate. People that were my age and older, but we all shared the values of believing in
creating a future for us.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/climathon-2021/1.JPG"
width="6000"
height="4000"
srcset="https://sebo-the-tramp.github.io/03_projects/climathon-2021/1_hu12798880398592588725.JPG 480w, https://sebo-the-tramp.github.io/03_projects/climathon-2021/1_hu9100913166263507197.JPG 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
> &lt;img src="https://sebo-the-tramp.github.io/03_projects/climathon-2021/2.jpg"
width="3000"
height="2000"
srcset="https://sebo-the-tramp.github.io/03_projects/climathon-2021/2_hu4192942707034979978.jpg 480w, https://sebo-the-tramp.github.io/03_projects/climathon-2021/2_hu2163928554497404874.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
> &lt;img src="https://sebo-the-tramp.github.io/03_projects/climathon-2021/3.jpg"
width="3000"
height="2000"
srcset="https://sebo-the-tramp.github.io/03_projects/climathon-2021/3_hu7833579340944966572.jpg 480w, https://sebo-the-tramp.github.io/03_projects/climathon-2021/3_hu1885619720831060021.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
> &lt;img src="https://sebo-the-tramp.github.io/03_projects/climathon-2021/4.jpg"
width="3000"
height="2000"
srcset="https://sebo-the-tramp.github.io/03_projects/climathon-2021/4_hu12228255132404589291.jpg 480w, https://sebo-the-tramp.github.io/03_projects/climathon-2021/4_hu11023659946460863826.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;p>And now after 1 year we are organizing it again! Will you be part of this journey and this adventure?&lt;/p>
&lt;p>Check our website in the future to be able to save your spot at Climathon Predazzo 2023.&lt;/p>
&lt;p>P.S. Small spoiler: It will be around the end of September, beginning of October.&lt;/p></description></item></channel></rss>