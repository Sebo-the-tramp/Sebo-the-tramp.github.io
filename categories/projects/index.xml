<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Sebastian Cavada</title><link>https://sebo-the-tramp.github.io/categories/projects/</link><description>Recent content in Projects on Sebastian Cavada</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 01 Oct 2024 10:21:13 +0200</lastBuildDate><atom:link href="https://sebo-the-tramp.github.io/categories/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>TinySplat</title><link>https://sebo-the-tramp.github.io/03_projects/tiny-splat/</link><pubDate>Tue, 01 Oct 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/tiny-splat/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/tinysplat_small.jpg" alt="Featured image of post TinySplat" />&lt;h1 id="tinysplat">Tinysplat
&lt;/h1>&lt;p>During my the journey to understand Gaussian Splatting, I created Tinysplat as a hands-on project to explore its foundational concepts. By breaking down the complex process into more manageable parts, I aimed to simplify and clarify the underlying mechanisms. In this post, I’ll share the insights and discoveries I’ve made along the way, shedding light on the essentials of Gaussian Splatting through the lens of my experience with Tinysplat.&lt;/p>
&lt;h2 id="what-is-gaussian-splatting">What is Gaussian Splatting?
&lt;/h2>&lt;p>Gaussian splatting is a novel explicit surface representation developed to represent the 3D structure of an object or an environment and then convert (rasterize) them into 2D images to be shown on our screens.&lt;/p>
&lt;p>The 2 most important pieces of this concept are: Gaussian and Splatting.&lt;/p>
&lt;h3 id="gaussians">Gaussians
&lt;/h3>&lt;p>Gaussians is a shorthand for Gaussian distribution, which we are familiar from statistics in 1 dimension. Hold tight because in this process the dimensions of the Gaussian distribution will go up to 2 and 3. The most intuitive way to think of a Gaussian in 3 dimensions (with a lot of abuse in notation) is to think about it as a balloon. Of this balloon we can control different proprieties such as the rotation, the color, the size, by inflating it more or less etc.
Turns out that in the Gaussian Splatting process, we build the environment by merging together many of these balloons of different dimensions and colors at different positions in the space. Take a look at the following image:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower_hu3943403685022499734.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/flower_hu2712116330969510316.jpeg 1024w"
loading="lazy"
alt="&amp;ldquo;The first Gaussian flower - an abstract way of thinking about Gaussian splatting&amp;rdquo;"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>You can think of a car being made of many balloons at different positions and different sizes and colors, but then you can observe this shape from many points and always understand that this is a car.
And this brings us to the second key concept: splatting.&lt;/p>
&lt;h3 id="splatting">Splatting
&lt;/h3>&lt;p>Splatting is not a new concept and it refers to the technique of rendering each pixel on your monitor as the combination of many Gaussian-shaped &amp;ldquo;splats&amp;rdquo; (or balloons) by blending each contribution of each balloon given the camera position.
You might wonder what is special about this technique. Well in a single words it is DIFFERENTIABLE. It means that we can run back-propagation to whatever loss we have and therefore manipulating the properties of every balloons in our scene. To some degree we can think of differentiability as being a human inside the room that can listen to our commands shouting from a small window telling him where he should move every balloon to create an object. Without differentiability we would not have a way to communicate to the person inside.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation_hu6562073399138009442.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/explanation_hu14846136555838797151.jpeg 1024w"
loading="lazy"
alt="Communication between the &amp;ldquo;Representation&amp;rdquo; on the left and the &amp;ldquo;Loss&amp;rdquo; on the right"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>Imagine there is no &amp;ldquo;open window&amp;rdquo; and no way for the two guys to communicate. Then the process will be NON differentiable. It is exactly the communication that was the key to enable many interesting applications of Gaussian splatting. Remember &amp;ldquo;Communication is key&amp;rdquo;.&lt;/p>
&lt;h2 id="but-why">But why?
&lt;/h2>&lt;p>Then you might ask why do we need to have a man inside a house inflating balloons and one guy outside observing and shouting?! Well that&amp;rsquo;s a fair question.&lt;/p>
&lt;p>In proper terminology what this techniques enable is to learn from just a handful of images, on the order of the hundreds, a whole object or environment, so hopefully we can generate &amp;ldquo;novel views&amp;rdquo;. This fancy term refers basically that we can generate a rough 3D reconstruction from these images.
Again in technical terms we are over-fitting a scene or also inferring from the images we have at our disposal, what would the image look like from a completely different point of view that we didn&amp;rsquo;t have before.&lt;/p>
&lt;p>In conclusion this technique is called explicit neural radiance Field. The explicit term references the fact that the parameters of the Gaussians are stored as is, and in the weights as in the NeRF representation for example. Radiance field instead is just a fancy word that was chosen to describe the way that rays are captured by the camera coming from all the scene.&lt;/p>
&lt;h2 id="okay-balloons-and-communication-now-what">Okay, balloons and communication, now what?
&lt;/h2>&lt;p>This is a legit question. How do we even generate these Gaussians, and even how do we position them? We don&amp;rsquo;t have a human in the computer, let alone 2 people communicating!&lt;/p>
&lt;p>The journey of creating a realistic scene is split into 2 parts:&lt;/p>
&lt;ol>
&lt;li>Initialization of the priors&lt;/li>
&lt;li>Fitting of the priors onto the images&lt;/li>
&lt;/ol>
&lt;h3 id="priors-initialization">Priors initialization
&lt;/h3>&lt;p>Gaussian splatting works better if we have already a rough idea of what the scene looks like. Imagine having some rough sketch of what you want, it is going to be easier to realize your masterpiece. In the same way, Gaussian Splatting works best when our initial sketch is a Point Cloud. A point cloud is exactly a way to define a rough sketch of the scene.&lt;/p>
&lt;p>The most common way to obtain is to run an algorithm called Structure from Motion. In other words given images of the scene from different positions it will triangulate the points and create a 3D representation which is close enough to reality. These methods are still improving and there is no best approach but it depends on many factors such as dimensions, motions etc. In the end this is still an open research question, therefore many more options (hopefully) are coming every month.&lt;/p>
&lt;p>Here you can have a look of what that means. The red &amp;ldquo;things&amp;rdquo; (camera frustums), represent the rotation and position of the cameras in space, whilst the points (which should be colored), they represent the 4D space that was reconstructed. It is called &amp;ldquo;sparse&amp;rdquo; reconstruction because as you might have noticed, it is missing a lot of points, but the 3D high level idea can be interpreted by a human at least.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example.png"
width="1559"
height="1028"
srcset="https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example_hu9886606328979335903.png 480w, https://sebo-the-tramp.github.io/03_projects/tiny-splat/sfm_example_hu15624097298807457446.png 1024w"
loading="lazy"
alt="Structure from motion from the Abu Dhabi F1 circuit"
class="gallery-image"
data-flex-grow="151"
data-flex-basis="363px"
>&lt;/p>
&lt;p>Once this rough initialization has been created is time to go to next step.&lt;/p>
&lt;h3 id="fitting-of-the-gaussians-more-technical">Fitting of the Gaussians (more technical)
&lt;/h3>&lt;p>This part is the most mindblowing and difficult, so take a deep breath and let&amp;rsquo;s dive into cold waters.&lt;/p>
&lt;p>Now that we have some images, the position and rotation of the cameras, where the image was taken and the priors point cloud, the real training begins.&lt;/p>
&lt;p>It works very similar as in neural networks, where we have a set of parameters that needs to optimized using some gradient descent algorithm such as SGD. In this case all gaussians are initialized with the color and point in 3D space provided by the SfM algorithm. The scale and rotations are initialized as standard values such as 1.&lt;/p>
&lt;p>During training we use these values to create and project the Gaussians onto the screen in a &lt;strong>differentiable manner&lt;/strong>. This will produce some strange images at first, by projecting all the gaussians to the screen that is orientated and positioned in the same way as the way the image was taken.&lt;/p>
&lt;p>This way we have a reference of what the image should be at that position, and what we actually get from the &amp;ldquo;splatting&amp;rdquo; process. Now you might have understood already, we can calculate a &lt;strong>loss&lt;/strong> or &lt;strong>difference&lt;/strong> in similarity between the two images. There are 2 ways this difference is computed, and usually is a combination of different losses such as f1 loss, and SSIM loss, where $\lambda$ is a parameter used to balance the two accuracies.&lt;/p>
&lt;p>$$
(1 - \lambda) * \text{F1-loss(img1, img2)} + \lambda * \text{SSIM(img1, img2)}
$$&lt;/p>
&lt;p>In this way iterating over the many images in the dataset, batch by batch, we can optimize the parameters of the whole number of Gaussians by backpropagating the error back to each gaussian based on the (sum) of the error(s) from every pixel in each image.
By optimizing these parameters, after some epochs, a clear image can be seen. A 2D example is displayed below. What you see is a video of the training where the Gaussians gets progressively refined and the final result is a sharp and crisp image.&lt;/p>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4"
poster="./flower.jpeg"
autoplay
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;p>(&lt;em>Video courtesy of&lt;/em> &lt;a class="link" href="https://github.com/OutofAi/2D-Gaussian-Splatting" target="_blank" rel="noopener"
>OutOfAI&lt;/a>)&lt;/p>
&lt;h3 id="final-thoughts">Final thoughts
&lt;/h3>&lt;p>This is a good introductory article to Gaussian splatting in a non-technical way. If you would like to dig deeper into the topics I am compiling a series of blog post where I show the implementation of Gaussian Splatting in 2D &lt;a class="link" href="https://sebo-the-tramp.github.io/04_notebook/tinysplat/" target="_blank" rel="noopener"
>here&lt;/a> and in the future also in 3D.&lt;/p>
&lt;p>I will leave another list of good material that helped me understand better the topic. Let me know if this was helpful, and especially how I can improve!&lt;/p></description></item><item><title>TinySplat</title><link>https://sebo-the-tramp.github.io/p/tiny-splat/</link><pubDate>Tue, 01 Oct 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/p/tiny-splat/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/p/tiny-splat/tinysplat_small.jpg" alt="Featured image of post TinySplat" />&lt;h1 id="tinysplat">Tinysplat
&lt;/h1>&lt;p>During my the journey to understand Gaussian Splatting, I created Tinysplat as a hands-on project to explore its foundational concepts. By breaking down the complex process into more manageable parts, I aimed to simplify and clarify the underlying mechanisms. In this post, I’ll share the insights and discoveries I’ve made along the way, shedding light on the essentials of Gaussian Splatting through the lens of my experience with Tinysplat.&lt;/p>
&lt;h2 id="what-is-gaussian-splatting">What is Gaussian Splatting?
&lt;/h2>&lt;p>Gaussian splatting is a novel explicit surface representation developed to represent the 3D structure of an object or an environment and then convert (rasterize) them into 2D images to be shown on our screens.&lt;/p>
&lt;p>The 2 most important pieces of this concept are: Gaussian and Splatting.&lt;/p>
&lt;h3 id="gaussians">Gaussians
&lt;/h3>&lt;p>Gaussians is a shorthand for Gaussian distribution, which we are familiar from statistics in 1 dimension. Hold tight because in this process the dimensions of the Gaussian distribution will go up to 2 and 3. The most intuitive way to think of a Gaussian in 3 dimensions (with a lot of abuse in notation) is to think about it as a balloon. Of this balloon we can control different proprieties such as the rotation, the color, the size, by inflating it more or less etc.
Turns out that in the Gaussian Splatting process, we build the environment by merging together many of these balloons of different dimensions and colors at different positions in the space. Take a look at the following image:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/p/tiny-splat/flower.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/p/tiny-splat/flower_hu3943403685022499734.jpeg 480w, https://sebo-the-tramp.github.io/p/tiny-splat/flower_hu2712116330969510316.jpeg 1024w"
loading="lazy"
alt="&amp;ldquo;The first Gaussian flower - an abstract way of thinking about Gaussian splatting&amp;rdquo;"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>You can think of a car being made of many balloons at different positions and different sizes and colors, but then you can observe this shape from many points and always understand that this is a car.
And this brings us to the second key concept: splatting.&lt;/p>
&lt;h3 id="splatting">Splatting
&lt;/h3>&lt;p>Splatting is not a new concept and it refers to the technique of rendering each pixel on your monitor as the combination of many Gaussian-shaped &amp;ldquo;splats&amp;rdquo; (or balloons) by blending each contribution of each balloon given the camera position.
You might wonder what is special about this technique. Well in a single words it is DIFFERENTIABLE. It means that we can run back-propagation to whatever loss we have and therefore manipulating the properties of every balloons in our scene. To some degree we can think of differentiability as being a human inside the room that can listen to our commands shouting from a small window telling him where he should move every balloon to create an object. Without differentiability we would not have a way to communicate to the person inside.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/p/tiny-splat/explanation.jpeg"
width="1024"
height="1024"
srcset="https://sebo-the-tramp.github.io/p/tiny-splat/explanation_hu6562073399138009442.jpeg 480w, https://sebo-the-tramp.github.io/p/tiny-splat/explanation_hu14846136555838797151.jpeg 1024w"
loading="lazy"
alt="Communication between the &amp;ldquo;Representation&amp;rdquo; on the left and the &amp;ldquo;Loss&amp;rdquo; on the right"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;p>Imagine there is no &amp;ldquo;open window&amp;rdquo; and no way for the two guys to communicate. Then the process will be NON differentiable. It is exactly the communication that was the key to enable many interesting applications of Gaussian splatting. Remember &amp;ldquo;Communication is key&amp;rdquo;.&lt;/p>
&lt;h2 id="but-why">But why?
&lt;/h2>&lt;p>Then you might ask why do we need to have a man inside a house inflating balloons and one guy outside observing and shouting?! Well that&amp;rsquo;s a fair question.&lt;/p>
&lt;p>In proper terminology what this techniques enable is to learn from just a handful of images, on the order of the hundreds, a whole object or environment, so hopefully we can generate &amp;ldquo;novel views&amp;rdquo;. This fancy term refers basically that we can generate a rough 3D reconstruction from these images.
Again in technical terms we are over-fitting a scene or also inferring from the images we have at our disposal, what would the image look like from a completely different point of view that we didn&amp;rsquo;t have before.&lt;/p>
&lt;p>In conclusion this technique is called explicit neural radiance Field. The explicit term references the fact that the parameters of the Gaussians are stored as is, and in the weights as in the NeRF representation for example. Radiance field instead is just a fancy word that was chosen to describe the way that rays are captured by the camera coming from all the scene.&lt;/p>
&lt;h2 id="okay-balloons-and-communication-now-what">Okay, balloons and communication, now what?
&lt;/h2>&lt;p>This is a legit question. How do we even generate these Gaussians, and even how do we position them? We don&amp;rsquo;t have a human in the computer, let alone 2 people communicating!&lt;/p>
&lt;p>The journey of creating a realistic scene is split into 2 parts:&lt;/p>
&lt;ol>
&lt;li>Initialization of the priors&lt;/li>
&lt;li>Fitting of the priors onto the images&lt;/li>
&lt;/ol>
&lt;h3 id="priors-initialization">Priors initialization
&lt;/h3>&lt;p>Gaussian splatting works better if we have already a rough idea of what the scene looks like. Imagine having some rough sketch of what you want, it is going to be easier to realize your masterpiece. In the same way, Gaussian Splatting works best when our initial sketch is a Point Cloud. A point cloud is exactly a way to define a rough sketch of the scene.&lt;/p>
&lt;p>The most common way to obtain is to run an algorithm called Structure from Motion. In other words given images of the scene from different positions it will triangulate the points and create a 3D representation which is close enough to reality. These methods are still improving and there is no best approach but it depends on many factors such as dimensions, motions etc. In the end this is still an open research question, therefore many more options (hopefully) are coming every month.&lt;/p>
&lt;p>Here you can have a look of what that means. The red &amp;ldquo;things&amp;rdquo; (camera frustums), represent the rotation and position of the cameras in space, whilst the points (which should be colored), they represent the 4D space that was reconstructed. It is called &amp;ldquo;sparse&amp;rdquo; reconstruction because as you might have noticed, it is missing a lot of points, but the 3D high level idea can be interpreted by a human at least.&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/p/tiny-splat/sfm_example.png"
width="1559"
height="1028"
srcset="https://sebo-the-tramp.github.io/p/tiny-splat/sfm_example_hu9886606328979335903.png 480w, https://sebo-the-tramp.github.io/p/tiny-splat/sfm_example_hu15624097298807457446.png 1024w"
loading="lazy"
alt="Structure from motion from the Abu Dhabi F1 circuit"
class="gallery-image"
data-flex-grow="151"
data-flex-basis="363px"
>&lt;/p>
&lt;p>Once this rough initialization has been created is time to go to next step.&lt;/p>
&lt;h3 id="fitting-of-the-gaussians-more-technical">Fitting of the Gaussians (more technical)
&lt;/h3>&lt;p>This part is the most mindblowing and difficult, so take a deep breath and let&amp;rsquo;s dive into cold waters.&lt;/p>
&lt;p>Now that we have some images, the position and rotation of the cameras, where the image was taken and the priors point cloud, the real training begins.&lt;/p>
&lt;p>It works very similar as in neural networks, where we have a set of parameters that needs to optimized using some gradient descent algorithm such as SGD. In this case all gaussians are initialized with the color and point in 3D space provided by the SfM algorithm. The scale and rotations are initialized as standard values such as 1.&lt;/p>
&lt;p>During training we use these values to create and project the Gaussians onto the screen in a &lt;strong>differentiable manner&lt;/strong>. This will produce some strange images at first, by projecting all the gaussians to the screen that is orientated and positioned in the same way as the way the image was taken.&lt;/p>
&lt;p>This way we have a reference of what the image should be at that position, and what we actually get from the &amp;ldquo;splatting&amp;rdquo; process. Now you might have understood already, we can calculate a &lt;strong>loss&lt;/strong> or &lt;strong>difference&lt;/strong> in similarity between the two images. There are 2 ways this difference is computed, and usually is a combination of different losses such as f1 loss, and SSIM loss, where $\lambda$ is a parameter used to balance the two accuracies.&lt;/p>
&lt;p>$$
(1 - \lambda) * \text{F1-loss(img1, img2)} + \lambda * \text{SSIM(img1, img2)}
$$&lt;/p>
&lt;p>In this way iterating over the many images in the dataset, batch by batch, we can optimize the parameters of the whole number of Gaussians by backpropagating the error back to each gaussian based on the (sum) of the error(s) from every pixel in each image.
By optimizing these parameters, after some epochs, a clear image can be seen. A 2D example is displayed below. What you see is a video of the training where the Gaussians gets progressively refined and the final result is a sharp and crisp image.&lt;/p>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4"
poster="./flower.jpeg"
autoplay
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://sebo-the-tramp.github.io/p/tiny-splat/video.mp4">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;p>(&lt;em>Video courtesy of&lt;/em> &lt;a class="link" href="https://github.com/OutofAi/2D-Gaussian-Splatting" target="_blank" rel="noopener"
>OutOfAI&lt;/a>)&lt;/p>
&lt;h3 id="final-thoughts">Final thoughts
&lt;/h3>&lt;p>This is a good introductory article to Gaussian splatting in a non-technical way. If you would like to dig deeper into the topics I am compiling a series of blog post where I show the implementation of Gaussian Splatting in 2D &lt;a class="link" href="https://sebo-the-tramp.github.io/04_notebook/tinysplat/" target="_blank" rel="noopener"
>here&lt;/a> and in the future also in 3D.&lt;/p>
&lt;p>I will leave another list of good material that helped me understand better the topic. Let me know if this was helpful, and especially how I can improve!&lt;/p></description></item><item><title>My first hackathon in the UAE - Pioneers 4.0 - (🏆 WINNER)</title><link>https://sebo-the-tramp.github.io/03_projects/edge-hackathon/</link><pubDate>Mon, 04 Mar 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/edge-hackathon/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image.png" alt="Featured image of post My first hackathon in the UAE - Pioneers 4.0 - (🏆 WINNER)" />&lt;h1 id="my-first-hackathon-in-the-uae">My first Hackathon in the UAE
&lt;/h1>&lt;p>I had the opportunity to participate in the Pioneers4.0 Hackathon, organized by the Edge together with MoAT and partner LIPTON tea. It was a 72-hour event, where we had to develop an optimization solution to optimize the production and blending of tea.&lt;/p>
&lt;p>I was part of a team of 5 people, and we were able to develop a solution that was able to optimize the production of tea, considering the different types of tea and the different blends that could be made. We used a simple rule-based algorithm to optimize the production and blending of tea, and we were able to present a working prototype at the end of the event.&lt;/p>
&lt;p>It was a great experience, and I was able to learn a lot about the tea industry and the challenges that the industry faces. I also learned a lot about the different types of tea and the different blends that can be made. It was a great opportunity to work with a team of people from different backgrounds and to learn from each other.&lt;/p>
&lt;p>We also managed to win the competition with a mix of team-work, creativity as well as technical skills. It was a great experience and I am looking forward to participating in more hackathons in the future.&lt;/p>
&lt;p>Thanks to the Edge and MoAT for organizing the event, and to LIPTON tea as well. I am looking forward to be part of the LIPTON team in the future, with the internship that I was awarded at the end of the event.&lt;/p>
&lt;p>Following some pictures of the event:&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image.png"
width="2996"
height="1096"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image_hu3037950491188731137.png 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/image_hu12029488097392795760.png 1024w"
loading="lazy"
alt="All the participants together on the stage"
class="gallery-image"
data-flex-grow="273"
data-flex-basis="656px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19.JPG"
width="3840"
height="2160"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19_hu7768972869191826713.JPG 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/4358450C-DA13-475C-9BA4-BC8770002C19_hu5647556701346842885.JPG 1024w"
loading="lazy"
alt="Our winning proof"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1.JPG"
width="4032"
height="2268"
srcset="https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1_hu13038122089877568271.JPG 480w, https://sebo-the-tramp.github.io/03_projects/edge-hackathon/089cbd28-e8b9-49dd-aff7-73d60c499fd1_hu17815644352049799312.JPG 1024w"
loading="lazy"
alt="Our amazing team, from left to right (people holding the cerificate): Luthfi Shahab, me, Segni Desalegn, Sara Abdulbasit, Mariam Alzaabi and Siti Maghfirotul Ulyah"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p></description></item><item><title>MBZUAI entrepreneurship school</title><link>https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/</link><pubDate>Sat, 20 Jan 2024 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846.jpeg" alt="Featured image of post MBZUAI entrepreneurship school" />&lt;p>🚀 A Milestone at the Entrepreneurship Pitch Day 🌟&lt;/p>
&lt;p>What an enriching experience for WellRound during last week&amp;rsquo;s Pitch Day organized by MBZUAI (Mohamed bin Zayed University of Artificial Intelligence) and startAD as the conclusion of the MBZUAI Entrepreneurship Course. Our journey was packed with learning and invaluable insights!&lt;/p>
&lt;p>The chance to present our AI-driven idea to the esteemed jury members Jean-Luc Scherer, Sultan Al Hajji, Selim Tira, Dr Ramzi BEN OUAGHREM and Michael Huang was both challenging and rewarding. Their feedback is a treasure trove, guiding our next steps.&lt;/p>
&lt;p>Kudos to everyone at StartAD for the great opportunity, in particular, a huge thanks to Flo Akinbiyi, Adnan Dekedek, and Jenny Li for their enthusiasm and expert guidance!&lt;/p>
&lt;p>A big shoutout to the winners for their amazing pitches and ideas, and to everyone that participated!&lt;/p>
&lt;p>My colleagues Akbobek Abilkaiyrkyzy, Sathya R, and I are already gearing up for our Wellround&amp;rsquo;s next iteration, inspired and more focused than ever.&lt;/p>
&lt;p>🔑 Key Takeaways:&lt;/p>
&lt;ul>
&lt;li>Embrace every piece of feedback for growth.&lt;/li>
&lt;li>Each pitch sharpens our vision and storytelling.&lt;/li>
&lt;li>Collaboration fuels innovation.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846.jpeg"
width="2048"
height="1152"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846_hu6257078364664368816.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553055846_hu976951420474417839.jpeg 1024w"
loading="lazy"
alt="All the 2023 fall class of the MBZUAI Entrepreneurship school"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531_hu7245333940414877949.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553050531_hu4621521240127584442.jpeg 1024w"
loading="lazy"
alt="Receiving the certificate"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940_hu16103162977852578918.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553058940_hu872847728078529929.jpeg 1024w"
loading="lazy"
alt="A cool photo! In reality I was really trembling"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219.jpeg"
width="2048"
height="1365"
srcset="https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219_hu162178263792267735.jpeg 480w, https://sebo-the-tramp.github.io/03_projects/mbzuai-entrepreneurship/1706553057219_hu6058965238694885698.jpeg 1024w"
loading="lazy"
alt="Our amazing team, from left to right: me, Akbobek Abilkaiyrkyzy and Sathyamoorthy Rajendran"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p></description></item><item><title>Euregio Brussels school</title><link>https://sebo-the-tramp.github.io/03_projects/contexts/</link><pubDate>Sat, 08 Apr 2023 10:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/03_projects/contexts/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/cover.jpeg" alt="Featured image of post Euregio Brussels school" />&lt;h1 id="part-1---the-plane">Part 1 - the plane
&lt;/h1>&lt;p>I am writing from the plane. I am in the first row in the middle. I feel I am very lucky. My week of lectures has ended this morning with a discussion on the migration problem in the EU. It was something I have never experienced because we had to take the side of the politicians that don’t accept or better want to protect the EU from immigration. Usually this is the opposite to what I think and it was good for me to push myself out of the bubble and try to see everything from a new prospective. I can’t lie that it was difficult to be in the shoes of people that uses hate and aversion towards the different and the unknown to get votes and get things done, because this is what it does boil down to.&lt;/p>
&lt;p>During this experience I really felt what it is to be on the other side and even more I realize how much I tend to be a “super-part” everyday life. Here is where the inception happens. Through meditation I learned to be equanimous and be balanced on most topics. Then reading the book “reality transurfing” in the past weeks I learned how wise and useful it is not to take any side in discussion or idealisms. And in the end this week I experienced the importance of taking a side and trying to be on the side of the right. And here I also see both the arguments to take a position and not to take a position. I am equanimous. According to the meditation we should always have in mind to reduce suffering and that’s what I have in mind for the future and I would always like to deploy all my resources towards this goal.
As a concluding anecdote, I wanted to share my experience with homeless people I met in Bruxelles, because yes where the most money are the most poverty is as well.&lt;/p>
&lt;p>This homeless people where there on the streets and I wanted to do anything to help. Probably I didn’t. I could have shared a loaf of bread that in the end I had to throw away. I could have brought them some items I have bought from too good to go, but I felt it was wrong and I felt embarrassed, but most of all I didn’t know if that was the right way to act. In this regard I think there is no, or very little, actions that can be done at that very moment to solve something, but I am a big fun of compounded interest and doing small, or big, things over a long period of time in order to really solve a problem.
This proved to be successful different times. Especially I realized this with my education: there was no single thing that I could have done different, because in the end they brought me at this point. Now I really want to focus only on a handful things, do them at a very high level and be able then to give value to many through my work and time. With this I want to say that we are in this together, we are all excellent at speaking or writing, but will we have the courage to act and really put our words into actions?&lt;/p>
&lt;p>I hope so and I will bring this experience with me and use it as a tool for my next decisions to be aligned with the goal of giving the most and making this place a little better because of my presence. If I could help a single person than my goal will be fulfilled.&lt;/p>
&lt;p>We are in a cloud now, there is some turbulence and I will have to close now.&lt;/p>
&lt;h1 id="part-2---the-train">Part 2 - the train
&lt;/h1>&lt;p>I start to write the second and conclusive part here in the train. I was able to get a good train going to Pandora and I am still active and I feel I would like to write or relax.
I still don’t believe what happened on the plane. It is so strange, yet so beautiful. Some times I think is karma other I just understand that it is only a coincidence. Maybe it was just how the algorithms of Ryanair works in assigning random places. Actually it probably don’t assign random all places but it will prefer the ones that has no additional value first. Then maybe I was a bit late for the check in and they first because all the others were already taken (?). This is a big supposition but I am grateful that happen, and at the same time I now realized that I should be equanimous and don’t crave this feelings but rather really live to the fullest every day.&lt;/p>
&lt;p>On this proposition I realized how better it is to really always try to live to the fullest. Life is short and it does not have any prefixed length. So living everyday in the present is the real life hack. And also memento more has become increasingly more important as if a person lives a life with a purpose and a direction whenever it will end it will be a good life. If someone might not have a purpose or direction that might be a bit more difficult.&lt;/p>
&lt;p>Let me know what you think in this regard in the comments and I will leave you with a couple of photos of my and our class in Bruxelles.&lt;/p>
&lt;p>Ciao!&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/e.jfif"
width="1600"
height="1200"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/e_hu722358435378867216.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/e_hu422797500594362348.jfif 1024w"
loading="lazy"
alt="At the EU Commission"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/c.jfif"
width="2000"
height="1500"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/c_hu12171015809121266458.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/c_hu9924231365313408728.jfif 1024w"
loading="lazy"
alt="At the Euregio representation in Bruxelles"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/d.jfif"
width="1600"
height="1200"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/d_hu15004275814929729284.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/d_hu753058859736929890.jfif 1024w"
loading="lazy"
alt="At the EU Parliament"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/b.jfif"
width="1024"
height="768"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/b_hu15812956490927628739.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/b_hu14911607811920133306.jfif 1024w"
loading="lazy"
alt="Chilling in the park"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>
&lt;img src="https://sebo-the-tramp.github.io/03_projects/contexts/a.jfif"
width="1024"
height="768"
srcset="https://sebo-the-tramp.github.io/03_projects/contexts/a_hu3636863013617844214.jfif 480w, https://sebo-the-tramp.github.io/03_projects/contexts/a_hu16046551133804725612.jfif 1024w"
loading="lazy"
alt="Chilling at the beer factory"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p></description></item></channel></rss>