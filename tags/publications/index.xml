<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Publications on Sebastian Cavada</title><link>https://sebo-the-tramp.github.io/tags/publications/</link><description>Recent content in Publications on Sebastian Cavada</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 18 Dec 2024 20:21:13 +0200</lastBuildDate><atom:link href="https://sebo-the-tramp.github.io/tags/publications/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://sebo-the-tramp.github.io/02_publications/cad_assistant/</link><pubDate>Wed, 18 Dec 2024 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/02_publications/cad_assistant/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/02_publications/cad_assistant/cad.png" alt="Featured image of post " />&lt;h3 id="iccv-2025">ICCV 2025
&lt;/h3>&lt;p>&lt;strong>CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers&lt;/strong>&lt;/p>
&lt;p>&lt;em>Dimitrios Mallis, Ahmet Serdar Karadeniz, Sebastian Cavada, Danila Rukhovich, Niki Foteinopoulou, Kseniya Cherenkova, Anis Kacem, Djamila Aouada&lt;/em>&lt;/p>
&lt;h2 id="abstract">Abstract
&lt;/h2>&lt;p>We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows.&lt;/p></description></item><item><title/><link>https://sebo-the-tramp.github.io/02_publications/all_languages-matter/</link><pubDate>Mon, 25 Nov 2024 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/02_publications/all_languages-matter/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/02_publications/all_languages-matter/all.png" alt="Featured image of post " />&lt;h3 id="cvpr-2025-highlight">CVPR 2025 Highlight
&lt;/h3>&lt;p>&lt;strong>All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages&lt;/strong>&lt;/p>
&lt;p>&lt;em>{Many authors}&lt;/em>&lt;/p>
&lt;h2 id="abstract">Abstract
&lt;/h2>&lt;p>Existing Large Multimodal Models (LMMs) generally focus on only a few regions and languages. As LMMs continue to improve, it is increasingly important to ensure they understand cultural contexts, respect local sensitivities, and support low-resource languages, all while effectively integrating corresponding visual cues. In pursuit of culturally diverse global multimodal models, our proposed All Languages Matter Benchmark (ALM-bench) represents the largest and most comprehensive effort to date for evaluating LMMs across 100 languages. ALM-bench challenges existing models by testing their ability to understand and reason about culturally diverse images paired with text in various languages, including many low-resource languages traditionally underrepresented in LMM research. The benchmark offers a robust and nuanced evaluation framework featuring various question formats, including true/false, multiple choice, and open-ended questions, which are further divided into short and long-answer categories. ALM-bench design ensures a comprehensive assessment of a model&amp;rsquo;s ability to handle varied levels of difficulty in visual and linguistic reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully curates content from 13 distinct cultural aspects, ranging from traditions and rituals to famous personalities and celebrations. Through this, ALM-bench not only provides a rigorous testing ground for state-of-the-art open and closed-source LMMs but also highlights the importance of cultural and linguistic inclusivity, encouraging the development of models that can serve diverse global populations effectively. Our benchmark is publicly available.&lt;/p></description></item><item><title/><link>https://sebo-the-tramp.github.io/02_publications/complexity_iaria/</link><pubDate>Tue, 17 Sep 2024 20:21:13 +0200</pubDate><guid>https://sebo-the-tramp.github.io/02_publications/complexity_iaria/</guid><description>&lt;img src="https://sebo-the-tramp.github.io/02_publications/complexity_iaria/complexity.png" alt="Featured image of post " />&lt;h3 id="-best-paper-award-">🏆 Best Paper Award 🎉
&lt;/h3>&lt;p>&lt;strong>Does Complexity Pay Off? Applying Advanced Algorithms to Depression Detection on the GLOBEM Dataset&lt;/strong>&lt;/p>
&lt;p>&lt;em>Sebastian Cavada, Alvaro Berobide, Yevheniia Kryklyvets&lt;/em>&lt;/p>
&lt;h2 id="abstract">Abstract
&lt;/h2>&lt;p>This manuscript evaluates the performance of state-of-the-art time series analysis algorithms for depression detection on the GLOBEM dataset. We assess TSMixer, Crossformer, GRU, CNN_LSTM and introduce a novel self-developed algorithm with the goal of increasing accuracy over the original Reorder. While these models demonstrate robust out-of-domain generalization, they fail to surpass the accuracy of the baseline Reorder algorithm, which was specifically developed for in-domain analysis by the GLOBEM team. Our findings reveal consistently low performance across all models, suggesting limitations inherent in the dataset rather than the algorithms themselves. We hypothesize that the dataset’s absence of critical variables and insufficient granularity likely limits model convergence. This hypothesis is supported by similar studies that achieved higher accuracy using more frequent data points with similar architecture approaches. Based on these insights, we suggest that future studies might benefit from incorporating more granular sensor measurements and more sophisticated data types such as, but not limited to, Heart Rate Variability (HRV)&lt;/p></description></item></channel></rss>